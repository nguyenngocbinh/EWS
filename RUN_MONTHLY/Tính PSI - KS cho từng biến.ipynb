{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import ks_2samp\n",
    "import matplotlib.pyplot as plt\n",
    "from sqlalchemy import create_engine, text\n",
    "from urllib.parse import quote\n",
    "from sklearn.metrics import roc_auc_score, roc_curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect SQL Server\n",
    "def get_data_from_sql_server():\n",
    "    server = 'VM-DC-JUMPSRV77\\IFRS9'\n",
    "    database = 'EWS'\n",
    "    user = 'rdm_admin'\n",
    "    pw = '2024#tpb'\n",
    "    driver = '{SQL Server}'\n",
    "    cnxn_str = f\"DRIVER={driver};SERVER={server};DATABASE={database};UID={user};PWD={pw}\"\n",
    "    engine = create_engine(f\"mssql+pyodbc:///?odbc_connect={quote(cnxn_str)}\")\n",
    "    # query\n",
    "    query = \"SELECT * FROM [EWS].[dbo].[ews_khdn_score_store] where model = 'B-score'\"\n",
    "    df = pd.read_sql(query, engine)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_ks(expected, actual):\n",
    "    ks_statistic, p_value = ks_2samp(expected, actual)\n",
    "    return ks_statistic, p_value   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import warnings\n",
    "\n",
    "def calculate_psi(expected, actual, categorical=False, bins=None):\n",
    "    # Check if the variables are categorical\n",
    "    if categorical:\n",
    "        # Get unique categories\n",
    "        categories = np.unique(np.concatenate([expected, actual]))\n",
    "\n",
    "        # Issue a warning if the number of unique categories exceeds 20\n",
    "        if len(categories) > 20:\n",
    "            warnings.warn(\"Warning: Number of unique categories exceeds 20.\")\n",
    "\n",
    "        # Calculate the expected and actual proportions for each category\n",
    "        expected_probs = np.array([np.sum(expected == cat) for cat in categories]) / len(expected)\n",
    "        actual_probs = np.array([np.sum(actual == cat) for cat in categories]) / len(actual)\n",
    "    else:\n",
    "        expected = expected[~np.isnan(expected)]\n",
    "        actual = actual[~np.isnan(actual)]\n",
    "        # Apply binning for numeric columns\n",
    "        if bins is None:\n",
    "            bins = 10  # Default to 10 bins, you can change this value as needed\n",
    "\n",
    "        # Calculate the bin edges based on percentiles\n",
    "        #bin_edges = np.percentile(np.hstack((expected, actual)), np.linspace(0, 100, bins + 1))\n",
    "        bin_edges = np.linspace(min(min(expected), min(actual)), max(max(expected), max(actual)), 11)\n",
    "        # Calculate the expected and actual proportions for each bin\n",
    "        expected_probs, _ = np.histogram(expected, bins=bin_edges)\n",
    "        actual_probs, _ = np.histogram(actual, bins=bin_edges)\n",
    "\n",
    "        # Normalize to get proportions\n",
    "        expected_probs = expected_probs / len(expected)\n",
    "        actual_probs = actual_probs / len(actual)\n",
    "        \n",
    "    # Initialize PSI\n",
    "    psi_value = 0\n",
    "\n",
    "    # Loop over each bin or category\n",
    "    for i in range(len(expected_probs)):\n",
    "        # Avoid division by zero and log of zero\n",
    "        if expected_probs[i] == 0 or actual_probs[i] == 0:\n",
    "            continue\n",
    "        # Calculate the PSI for this bin or category\n",
    "        psi_value += (expected_probs[i] - actual_probs[i]) * np.log(expected_probs[i] / actual_probs[i])\n",
    "\n",
    "    return psi_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    process_date criteria                           variable     value  \\\n",
      "0     2023-10-31      PSI                              grade  0.214822   \n",
      "1     2023-10-31      PSI                              score  0.015627   \n",
      "2     2023-10-31      PSI                     min_ca_bal_l6m  0.000017   \n",
      "3     2023-10-31      PSI                         vol_os_l6m  0.034919   \n",
      "4     2023-10-31      PSI                 num_cr_product_l3m  0.046908   \n",
      "..           ...      ...                                ...       ...   \n",
      "100   2023-12-31       KS                   num_xdpd_l6m_woe  0.069071   \n",
      "101   2023-12-31       KS                            dpd_woe  0.031376   \n",
      "102   2023-12-31       KS          avg_ebank_txn_amt_l3m_woe  0.340203   \n",
      "103   2023-12-31       KS             num_cr_product_l3m_woe  0.090125   \n",
      "104   2023-12-31       KS  avg_cash_txn_amt_per_time_l3m_woe  0.253500   \n",
      "\n",
      "        ks_pvalue  \n",
      "0             NaN  \n",
      "1             NaN  \n",
      "2             NaN  \n",
      "3             NaN  \n",
      "4             NaN  \n",
      "..            ...  \n",
      "100  1.416924e-25  \n",
      "101  1.290472e-05  \n",
      "102  0.000000e+00  \n",
      "103  2.874923e-43  \n",
      "104  0.000000e+00  \n",
      "\n",
      "[105 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "def calculate_psi_ks_by_process_date(df, quantitative_columns, categorical_columns):\n",
    "    psi_ks_table = pd.DataFrame(columns=['process_date', 'criteria', 'variable', 'value', 'ks_pvalue'])\n",
    "    df['process_date'] = pd.to_datetime(df['process_date'])\n",
    "    end_of_month_dates = pd.date_range(start='2023-10-31', end='2023-12-31', freq='M')\n",
    "    for process_date in end_of_month_dates:\n",
    "        # \n",
    "        data_before = df[(df['process_date'].dt.month == 12) & (df['process_date'].dt.year >= 2013) & (df['process_date'].dt.year <= 2019)]\n",
    "        data_after = df[df['process_date'] == process_date]\n",
    "        #\n",
    "        for column in categorical_columns:\n",
    "            actual = data_before[column].values\n",
    "            expected = data_after[column].values\n",
    "            psi_score = calculate_psi(expected, actual, categorical=True, bins=10)\n",
    "            psi_ks_table = psi_ks_table.append({'process_date': process_date,\n",
    "                                                'criteria': 'PSI',\n",
    "                                                'variable': column,\n",
    "                                                'value': psi_score},\n",
    "                                                ignore_index=True) \n",
    "\n",
    "        for column in quantitative_columns:\n",
    "            actual = data_before[column].values\n",
    "            expected = data_after[column].values\n",
    "            psi_score = calculate_psi(expected, actual, categorical=False, bins=10)\n",
    "            psi_ks_table = psi_ks_table.append({'process_date': process_date,\n",
    "                                                'criteria': 'PSI',\n",
    "                                                'variable': column,\n",
    "                                                'value': psi_score},\n",
    "                                                ignore_index=True)                                            \n",
    "\n",
    "        for column in quantitative_columns:\n",
    "            actual = data_after[column].values\n",
    "            expected = data_before[column].values\n",
    "            ks_statistic, p_value = calculate_ks(expected, actual)\n",
    "            psi_ks_table = psi_ks_table.append({'process_date': process_date,\n",
    "                                                'criteria': 'KS',\n",
    "                                                'variable': column,\n",
    "                                                'value': ks_statistic,\n",
    "                                                'ks_pvalue': p_value},\n",
    "                                                ignore_index=True)\n",
    "    \n",
    "    return psi_ks_table\n",
    "df = get_data_from_sql_server()\n",
    "# List các cột\n",
    "categorical_columns = ['grade']\n",
    "quantitative_columns = ['score',\n",
    "   'min_ca_bal_l6m'\n",
    "  ,  'vol_os_l6m'\n",
    "  ,  'num_cr_product_l3m'\n",
    "  ,  'dpd'\n",
    "  ,  'num_xdpd_l6m'\n",
    "  ,  'total_bal_os_onbs_avg'\n",
    "  ,  'avg_ebank_txn_amt_l3m'\n",
    "  ,  'avg_cash_txn_amt_per_time_l3m'\n",
    "  ,  'total_bal_os_onbs_avg_woe'\n",
    "  ,  'min_ca_bal_l6m_woe'\n",
    "  ,  'vol_os_l6m_woe'\n",
    "  ,  'num_xdpd_l6m_woe'\n",
    "  ,  'dpd_woe'\n",
    "  ,  'avg_ebank_txn_amt_l3m_woe'\n",
    "  ,  'num_cr_product_l3m_woe'\n",
    "  ,  'avg_cash_txn_amt_per_time_l3m_woe'\n",
    "     ]\n",
    "\n",
    "result_table = calculate_psi_ks_by_process_date(df, quantitative_columns, categorical_columns)\n",
    "print(result_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_table.to_excel('Z:/Noibo/PHONG MHRR/LanVH/PSI Bscore.xlsx', index= False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.5 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ad2bdc8ecc057115af97d19610ffacc2b4e99fae6737bb82f5d7fb13d2f2c186"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
